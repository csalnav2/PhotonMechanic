{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1sGzWESBtTDG2849poT6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csalnav2/PhotonMechanic/blob/main/LLMnodeprobe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit --quiet"
      ],
      "metadata": {
        "id": "PMwmE-AL4_H7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ce7e59-8c6d-41de-cbd7-4c453e608ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet # Install the pyngrok module\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "K4FDMuu6J2nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2tedizGJDmEJMDtfhCR6ftx8EyX_2RaA7t8nPn17SU7jiyK1H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Li4tEphLLWO",
        "outputId": "aabd7996-72a2-4376-c5f7-d3d4ba0b82a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 $(lsof -t -i:8000) 2>/dev/null || echo \"No existing process\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls_NhDtSLZvZ",
        "outputId": "6eff212c-599c-48d6-a128-4549ee928ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No existing process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet flask transformers torch networkx matplotlib scikit-learn safetensors pyvis soundfile psutil GPUtil\n",
        "# no dynamic quant error on GPU for int8 => fallback to CPU"
      ],
      "metadata": {
        "id": "4lA0OIYIUCWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44a1dfa-f18f-4e09-999a-e8ff1578c15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok"
      ],
      "metadata": {
        "id": "xH8QxPx04R5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# Single Cell or local Python script\n",
        "#   - Kills old processes on port=8000\n",
        "#   - Installs dependencies\n",
        "#   - Writes interpret_flask.py\n",
        "#   - Runs Flask in background\n",
        "#   - Polls for readiness or times out\n",
        "#   - Then starts ngrok\n",
        "# =============================================\n",
        "\n",
        "import os, time, requests\n",
        "\n",
        "print(\"ðŸ”´ Killing anything on port=8000 + old ngrok sessions.\")\n",
        "try:\n",
        "    get_ipython().system(\"pkill -f ngrok 2>/dev/null || echo 'No existing ngrok process.'\")\n",
        "    get_ipython().system(\"kill -9 $(lsof -t -i:8000) 2>/dev/null || echo 'No existing process.'\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print(\"ðŸ“¦ Installing dependencies (quietly)...\")\n",
        "try:\n",
        "    get_ipython().system(\"pip install --quiet flask transformers torch networkx matplotlib pyvis psutil requests pyngrok scipy GPUtil plotly\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "FULL_CODE = r'''\n",
        "###############################################################################\n",
        "# interpret_flask.py\n",
        "#\n",
        "# AI Interpretability web app with:\n",
        "#   - BFS layering\n",
        "#   - Shape-based memory estimates\n",
        "#   - More realistic time complexities based on node type + user-specified seq_len\n",
        "#   - Continuous drag => set target_mem/time\n",
        "#   - Automatic background convergence of mem/time\n",
        "#   - Real-time polling via /poll_compgraph_data => updates tooltips every 3s\n",
        "#   - BFS=0 layer route shows only BFS=0 input nodes\n",
        "###############################################################################\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import threading\n",
        "import traceback\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.fx as fx\n",
        "import networkx as nx\n",
        "import psutil\n",
        "import GPUtil\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from io import BytesIO\n",
        "from flask import Flask, request, send_file, jsonify, Response\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from pyvis.network import Network\n",
        "from scipy.interpolate import griddata\n",
        "import csv\n",
        "import json\n",
        "import requests\n",
        "\n",
        "app = Flask(__name__, static_folder=\"static\")\n",
        "if not os.path.exists(\"static\"):\n",
        "    os.makedirs(\"static\")\n",
        "\n",
        "################################################\n",
        "# GLOBALS\n",
        "################################################\n",
        "\n",
        "RL_CHOICE = \"No RL\"\n",
        "HYP_GRAPH = None\n",
        "COMP_GRAPH = None\n",
        "OLD_HYP_GRAPH = None\n",
        "OLD_COMP_GRAPH = None\n",
        "\n",
        "MODEL_CACHE = {}\n",
        "CONVERSATION = []\n",
        "COMP_SHAPE_INFO = {}  # { \"COMP_nodeName\": (in_shape, out_shape) }\n",
        "\n",
        "# Q_TABLE => 10 states, each with 4 actions\n",
        "Q_TABLE = {s:[random.uniform(-1,1) for _ in range(4)] for s in range(10)}\n",
        "\n",
        "GPU_MEMORY_SCALE = {\n",
        "    \"T4\":1.0,\n",
        "    \"A100\":0.5,\n",
        "    \"V100\":0.7,\n",
        "    \"TPU\":0.4\n",
        "}\n",
        "\n",
        "AVAILABLE_MODELS = {\n",
        "    \"BERT (base)\":\"bert-base-uncased\",\n",
        "    \"GPT-2\":\"gpt2\",\n",
        "    \"DistilBERT\":\"distilbert-base-uncased\"\n",
        "}\n",
        "AVAILABLE_GPUS = [\"T4\",\"A100\",\"V100\",\"TPU\"]\n",
        "QUANT_METHODS = [\"None (FP32)\",\"FP16\",\"INT8\"]\n",
        "REASONING_METHODS = [\n",
        "    \"No reasoning\",\n",
        "    \"Monte Carlo Tree Search (MCTS)\",\n",
        "    \"Chain of Thought (CoT)\",\n",
        "    \"Meta-CoT\",\n",
        "    \"Neural-Symbolic\"\n",
        "]\n",
        "RL_ALGORITHMS = [\n",
        "    \"No RL\",\n",
        "    \"Q-Learning\",\n",
        "    \"Deep Q-Network (DQN)\",\n",
        "    \"Policy Gradient\",\n",
        "    \"Actor-Critic\",\n",
        "    \"PPO\"\n",
        "]\n",
        "\n",
        "###############################################################################\n",
        "# TORCH FX SHAPE TRACING\n",
        "###############################################################################\n",
        "\n",
        "def trace_model_fx(model, tokenizer):\n",
        "    device = next(model.parameters()).device\n",
        "    wrap = ModelWrapper(model, tokenizer).to(device)\n",
        "    enc = tokenizer(\"Hello world!\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    shape_info = {}\n",
        "    try:\n",
        "        traced = fx.symbolic_trace(\n",
        "            wrap,\n",
        "            concrete_args={\n",
        "                \"input_ids\": enc[\"input_ids\"],\n",
        "                \"attention_mask\": enc.get(\"attention_mask\", None)\n",
        "            }\n",
        "        )\n",
        "        from torch.fx.passes.shape_prop import ShapeProp\n",
        "        sp = ShapeProp(traced)\n",
        "        sp.run(enc)\n",
        "\n",
        "        for node in traced.graph.nodes:\n",
        "            node_name = str(node)\n",
        "            in_shape  = \"?\"\n",
        "            out_shape = \"?\"\n",
        "            try:\n",
        "                if \"tensor_meta\" in node.meta:\n",
        "                    out_shape = tuple(node.meta[\"tensor_meta\"].shape)\n",
        "            except:\n",
        "                pass\n",
        "            shape_info[node_name] = (in_shape, out_shape)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return shape_info\n",
        "\n",
        "def estimate_gpu_memory(node_name, shape_tuple):\n",
        "    \"\"\"Rough memory estimate in KB for the output shape.\"\"\"\n",
        "    if not isinstance(shape_tuple, tuple):\n",
        "        return \"Unknown\"\n",
        "    numel = 1\n",
        "    for dim in shape_tuple:\n",
        "        numel *= dim\n",
        "    mem_kb = (numel * 4) / 1024  # FP32 = 4 bytes\n",
        "    return f\"{mem_kb:.1f}\"\n",
        "\n",
        "def interpret_operation(node_name):\n",
        "    \"\"\"Heuristic parse of node_name -> operation type (for table in glossary).\"\"\"\n",
        "    low = node_name.lower()\n",
        "    if \"matmul\" in low:\n",
        "        return \"MatrixMultiplication\"\n",
        "    elif \"transpose\" in low:\n",
        "        return \"Transpose\"\n",
        "    elif \"softmax\" in low:\n",
        "        return \"Softmax\"\n",
        "    elif \"norm\" in low:\n",
        "        return \"LayerNorm\"\n",
        "    elif \"activation\" in low or \"gelu\" in low or \"relu\" in low:\n",
        "        return \"Activation\"\n",
        "    elif \"linear\" in low or \"dense\" in low:\n",
        "        return \"Linear\"\n",
        "    elif \"dropout\" in low:\n",
        "        return \"Dropout\"\n",
        "    elif \"pooler\" in low or \"pool\" in low:\n",
        "        return \"Pooling\"\n",
        "    elif \"attention\" in low:\n",
        "        return \"Attention block\"\n",
        "    elif \"embedding\" in low:\n",
        "        return \"Embedding\"\n",
        "    return \"Generic op\"\n",
        "\n",
        "###############################################################################\n",
        "# MODEL UTILS\n",
        "###############################################################################\n",
        "\n",
        "def load_model(hf_id, quant=\"None (FP32)\"):\n",
        "    import torch.nn as nn\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if quant==\"INT8\" and device==\"cuda\":\n",
        "        device=\"cpu\"\n",
        "\n",
        "    cache_key = f\"{hf_id}_{quant}_{device}\"\n",
        "    if cache_key in MODEL_CACHE:\n",
        "        return MODEL_CACHE[cache_key][\"model\"], MODEL_CACHE[cache_key][\"tokenizer\"]\n",
        "\n",
        "    model = AutoModel.from_pretrained(hf_id)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(hf_id)\n",
        "    if quant==\"FP16\":\n",
        "        model = model.half()\n",
        "    elif quant==\"INT8\":\n",
        "        model = torch.quantization.quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "    model.eval()\n",
        "    if quant!=\"INT8\":\n",
        "        model.to(device)\n",
        "\n",
        "    MODEL_CACHE[cache_key] = {\"model\": model, \"tokenizer\": tokenizer}\n",
        "    return model, tokenizer\n",
        "\n",
        "###############################################################################\n",
        "# APPROX TIME COMPLEXITY\n",
        "###############################################################################\n",
        "def approximate_time_complexity(node_str, reasoning, seq_len):\n",
        "    \"\"\"\n",
        "    A toy function that tries to reflect different complexities.\n",
        "    - If \"attention\" or \"matmul\" => O(n^2)\n",
        "    - If \"embedding\", \"norm\", \"linear\", \"pool\" => O(n)\n",
        "    - If \"sparseattn\" => O(n log n) as a possible example\n",
        "    - Then we also scale by reasoning method\n",
        "    \"\"\"\n",
        "    low = node_str.lower()\n",
        "\n",
        "    # Base complexity factor from node type\n",
        "    # We'll just treat them as integer \"costs\" for demonstration.\n",
        "    base = 1\n",
        "    if \"attention\" in low or \"matmul\" in low:\n",
        "        # e.g. O(n^2) => we do seq_len^2\n",
        "        base = seq_len*seq_len\n",
        "    elif \"sparse\" in low and \"attn\" in low:\n",
        "        # e.g. O(n log n)\n",
        "        import math\n",
        "        base = int(seq_len * np.log2(seq_len+1))\n",
        "    elif \"embedding\" in low or \"norm\" in low or \"linear\" in low or \"pool\" in low:\n",
        "        # O(n)\n",
        "        base = seq_len\n",
        "    else:\n",
        "        # Just a constant\n",
        "        base = 1\n",
        "\n",
        "    # Reasoning multiplier\n",
        "    # This is totally arbitrary, just to illustrate synergy with \"reasoning\" field\n",
        "    mul = 1\n",
        "    if reasoning==\"Monte Carlo Tree Search (MCTS)\":\n",
        "        mul = 2\n",
        "    elif reasoning==\"Chain of Thought (CoT)\":\n",
        "        mul = 3\n",
        "    elif reasoning==\"Meta-CoT\":\n",
        "        mul = 4\n",
        "    elif reasoning==\"Neural-Symbolic\":\n",
        "        mul = 5\n",
        "\n",
        "    return base * mul\n",
        "\n",
        "def toy_finetune(model):\n",
        "    device = next(model.parameters()).device\n",
        "    model.train()\n",
        "    x = torch.randint(0,1000,(2,8), device=device)\n",
        "    m = torch.ones_like(x)\n",
        "    out = model(input_ids=x, attention_mask=m)\n",
        "    if isinstance(out, tuple) and out and isinstance(out[0], torch.Tensor):\n",
        "        loss = out[0].sum()\n",
        "    elif hasattr(out, \"last_hidden_state\"):\n",
        "        loss = out.last_hidden_state.sum()\n",
        "    else:\n",
        "        loss = torch.tensor(0.0, device=device)\n",
        "    optim = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    model.eval()\n",
        "\n",
        "class ModelWrapper(nn.Module):\n",
        "    def __init__(self, submodel, tokenizer):\n",
        "        super().__init__()\n",
        "        self.submodel = submodel\n",
        "        self.tokenizer = tokenizer\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        return self.submodel(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "###############################################################################\n",
        "# HYPERGRAPH\n",
        "###############################################################################\n",
        "\n",
        "def extract_hypergraph(model, quant, reasoning):\n",
        "    import networkx as nx\n",
        "    g = nx.Graph()\n",
        "    for name, module in model.named_modules():\n",
        "        node_name = \"HYP_\" + name\n",
        "        g.add_node(node_name)\n",
        "        if \".\" in name:\n",
        "            parent = \"HYP_\" + name.rsplit(\".\",1)[0]\n",
        "            child  = \"HYP_\" + name\n",
        "            g.add_edge(parent, child)\n",
        "    return g\n",
        "\n",
        "###############################################################################\n",
        "# COMP GRAPH BFS\n",
        "###############################################################################\n",
        "\n",
        "def fallback_comp_graph_for_gpt2(model, reasoning, gpu_sel):\n",
        "    import networkx as nx\n",
        "    scale_factor = GPU_MEMORY_SCALE.get(gpu_sel,1.0)\n",
        "    g = nx.Graph()\n",
        "    for name, module in model.named_modules():\n",
        "        node_name = \"COMP_\" + name\n",
        "        g.add_node(node_name,\n",
        "                   BFS_distance=0,\n",
        "                   mem=0,\n",
        "                   target_mem=0,\n",
        "                   timecost=0,\n",
        "                   target_time=0)\n",
        "        if \".\" in name:\n",
        "            parent = \"COMP_\" + name.rsplit(\".\",1)[0]\n",
        "            child  = \"COMP_\" + name\n",
        "            g.add_edge(parent, child)\n",
        "    return g\n",
        "\n",
        "def extract_comp_graph(model, tokenizer, gpu_sel, quant, reasoning):\n",
        "    import networkx as nx\n",
        "    import torch.fx as fx\n",
        "    device = next(model.parameters()).device\n",
        "    wrap = ModelWrapper(model, tokenizer).to(device)\n",
        "    enc  = tokenizer(\"Hello world!\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    try:\n",
        "        traced = fx.symbolic_trace(\n",
        "            wrap,\n",
        "            concrete_args={\n",
        "                \"input_ids\": enc[\"input_ids\"],\n",
        "                \"attention_mask\": enc.get(\"attention_mask\", None)\n",
        "            }\n",
        "        )\n",
        "        g = nx.Graph()\n",
        "        for node in traced.graph.nodes:\n",
        "            node_name = str(node)\n",
        "            nm = \"COMP_\" + node_name\n",
        "            g.add_node(nm,\n",
        "                       BFS_distance=0,\n",
        "                       mem=0,\n",
        "                       target_mem=0,\n",
        "                       timecost=0,\n",
        "                       target_time=0)\n",
        "        for node in traced.graph.nodes:\n",
        "            for user in node.users:\n",
        "                g.add_edge(\"COMP_\"+str(node), \"COMP_\"+str(user))\n",
        "        return g\n",
        "    except:\n",
        "        return fallback_comp_graph_for_gpt2(model, reasoning, gpu_sel)\n",
        "\n",
        "def compute_bfs_levels(nx_graph):\n",
        "    import networkx as nx\n",
        "    if nx_graph.number_of_nodes()==0:\n",
        "        return\n",
        "    root_candidates = [n for n in nx_graph.nodes if \"input\" in n.lower()]\n",
        "    if not root_candidates:\n",
        "        in_degs = nx_graph.in_degree()\n",
        "        zero_in = [nd for (nd,deg) in in_degs if deg==0]\n",
        "        if zero_in:\n",
        "            root_candidates= zero_in\n",
        "        else:\n",
        "            root_candidates= [list(nx_graph.nodes)[0]]\n",
        "    visited= set()\n",
        "    queue= []\n",
        "    for r in root_candidates:\n",
        "        queue.append((r,0))\n",
        "        nx_graph.nodes[r][\"BFS_distance\"]=0\n",
        "        visited.add(r)\n",
        "    while queue:\n",
        "        current, dist= queue.pop(0)\n",
        "        for neighbor in nx_graph.neighbors(current):\n",
        "            if neighbor not in visited:\n",
        "                visited.add(neighbor)\n",
        "                nx_graph.nodes[neighbor][\"BFS_distance\"]= dist+1\n",
        "                queue.append((neighbor, dist+1))\n",
        "\n",
        "def get_layer_subgraph(nx_graph, layer_num):\n",
        "    import networkx as nx\n",
        "    subg= nx.Graph()\n",
        "    if nx_graph.number_of_nodes()==0:\n",
        "        return subg\n",
        "    if \"BFS_distance\" not in list(nx_graph.nodes(data=True))[0][1]:\n",
        "        compute_bfs_levels(nx_graph)\n",
        "\n",
        "    # BFS=0 => only BFS=0 nodes\n",
        "    if layer_num == 0:\n",
        "        for n,d in nx_graph.nodes(data=True):\n",
        "            if d.get(\"BFS_distance\",None)==0:\n",
        "                subg.add_node(n,**d)\n",
        "        for (u,v) in nx_graph.edges():\n",
        "            if u in subg.nodes and v in subg.nodes:\n",
        "                subg.add_edge(u,v,**nx_graph[u][v])\n",
        "        return subg\n",
        "\n",
        "    for n,d in nx_graph.nodes(data=True):\n",
        "        if d.get(\"BFS_distance\",None)==layer_num:\n",
        "            subg.add_node(n,**d)\n",
        "    for (u,v) in nx_graph.edges():\n",
        "        if (u in subg.nodes) and (v in subg.nodes):\n",
        "            subg.add_edge(u,v,**nx_graph[u][v])\n",
        "    return subg\n",
        "\n",
        "################################################\n",
        "# Q-TABLE & RL\n",
        "################################################\n",
        "\n",
        "def update_q_table(state, action, reward):\n",
        "    old_val= Q_TABLE[state][action]\n",
        "    new_val= old_val + 0.1*(reward - old_val)\n",
        "    Q_TABLE[state][action]= new_val\n",
        "\n",
        "################################################\n",
        "# 2D & 3D Q-SPACE\n",
        "################################################\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "@app.route(\"/q_space\")\n",
        "def q_space():\n",
        "    states = sorted(Q_TABLE.keys())\n",
        "    xs,ys,zs= [],[],[]\n",
        "\n",
        "    for si,s in enumerate(states):\n",
        "        for ai,val in enumerate(Q_TABLE[s]):\n",
        "            xs.append(si)\n",
        "            ys.append(ai)\n",
        "            zs.append(val)\n",
        "    import numpy as np\n",
        "    xs= np.array(xs)\n",
        "    ys= np.array(ys)\n",
        "    zs= np.array(zs)\n",
        "\n",
        "    xi= np.linspace(xs.min(), xs.max(), 50)\n",
        "    yi= np.linspace(ys.min(), ys.max(), 50)\n",
        "    Xi,Yi= np.meshgrid(xi,yi)\n",
        "    from scipy.interpolate import griddata\n",
        "    Zi= griddata((xs,ys),zs,(Xi,Yi), method=\"cubic\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(4,4))\n",
        "    cont= ax.contourf(Xi,Yi,Zi,10,cmap=\"coolwarm\")\n",
        "    fig.colorbar(cont,ax=ax)\n",
        "    ax.set_xlabel(\"State\")\n",
        "    ax.set_ylabel(\"Action\")\n",
        "    ax.set_title(\"Q-Space Heatmap (2D)\")\n",
        "    ax.scatter(xs,ys,c=\"black\",s=15,marker=\"x\")\n",
        "\n",
        "    buf= BytesIO()\n",
        "    plt.savefig(buf, format=\"png\")\n",
        "    buf.seek(0)\n",
        "    plt.close(fig)\n",
        "    return send_file(buf, mimetype=\"image/png\")\n",
        "\n",
        "def polynomial_fit_r2(xs, ys, zs):\n",
        "    import numpy as np\n",
        "    X= np.column_stack((np.ones_like(xs), xs, ys, xs*xs, xs*ys, ys*ys))\n",
        "    coeffs,residuals,rank,s= np.linalg.lstsq(X,zs,rcond=None)\n",
        "    z_pred= X @ coeffs\n",
        "    ss_res= np.sum((zs - z_pred)**2)\n",
        "    ss_tot= np.sum((zs - np.mean(zs))**2)\n",
        "    if ss_tot<1e-12:\n",
        "        return 1.0\n",
        "    r2=1-(ss_res/ss_tot)\n",
        "    return r2\n",
        "\n",
        "@app.route(\"/q_space_interactive\")\n",
        "def q_space_interactive():\n",
        "    import numpy as np\n",
        "    states= sorted(Q_TABLE.keys())\n",
        "    xs,ys,zs= [],[],[]\n",
        "    for si,s in enumerate(states):\n",
        "        for ai,val in enumerate(Q_TABLE[s]):\n",
        "            xs.append(float(si))\n",
        "            ys.append(float(ai))\n",
        "            zs.append(val)\n",
        "    xs= np.array(xs)\n",
        "    ys= np.array(ys)\n",
        "    zs= np.array(zs)\n",
        "\n",
        "    minZ,maxZ= zs.min(), zs.max()\n",
        "    if abs(maxZ-minZ)<1e-9:\n",
        "        z_scaled= np.full_like(zs,4.5)\n",
        "    else:\n",
        "        z_scaled= 9.0*(zs-minZ)/(maxZ-minZ)\n",
        "\n",
        "    r2_value= polynomial_fit_r2(xs,ys,z_scaled)\n",
        "\n",
        "    Xi= np.linspace(0,9,10)\n",
        "    Yi= np.linspace(0,9,10)\n",
        "    XiGrid,YiGrid= np.meshgrid(Xi,Yi)\n",
        "    from scipy.interpolate import griddata\n",
        "    Zi= griddata((xs,ys),z_scaled,(XiGrid,YiGrid), method=\"cubic\")\n",
        "    if np.isnan(Zi).any():\n",
        "        Zi2= griddata((xs,ys),z_scaled,(XiGrid,YiGrid), method=\"nearest\")\n",
        "        Zi[np.isnan(Zi)] = Zi2[np.isnan(Zi)]\n",
        "\n",
        "    fig= go.Figure(data=[go.Surface(z=Zi,x=Xi,y=Yi,colorscale=\"Viridis\")])\n",
        "    fig.update_traces(contours_z=dict(show=True,usecolormap=True,highlightcolor=\"limegreen\",project_z=True))\n",
        "    fig.update_layout(\n",
        "        title=f\"3D Q-Space RÂ²={r2_value:.4f}\",\n",
        "        autosize=False,\n",
        "        width=700,\n",
        "        height=600,\n",
        "        margin=dict(l=65,r=50,b=65,t=90),\n",
        "        scene=dict(\n",
        "            xaxis=dict(title=\"State\", range=[0,9],autorange=False),\n",
        "            yaxis=dict(title=\"Action\", range=[0,9],autorange=False),\n",
        "            zaxis=dict(title=\"Q-Value\", range=[0,9],autorange=False),\n",
        "            camera=dict(eye=dict(x=1.6,y=1.6,z=1.2)),\n",
        "            aspectmode=\"cube\"\n",
        "        )\n",
        "    )\n",
        "    fig.update_layout(scene_dragmode=\"orbit\")\n",
        "\n",
        "    fig.write_html(\"static/qspace_3d.html\")\n",
        "    return f\"\"\"\n",
        "<h2>3D Q-Space</h2>\n",
        "<p>RÂ²={r2_value:.4f}</p>\n",
        "<iframe src=\"/static/qspace_3d.html\" width=\"700\" height=\"600\"></iframe>\n",
        "\"\"\"\n",
        "\n",
        "###############################################################################\n",
        "# SUBGRAPH + GLOSSARY\n",
        "###############################################################################\n",
        "\n",
        "def build_subgraph_hyper(original_graph, filter_str):\n",
        "    import networkx as nx\n",
        "    fl= filter_str.lower()\n",
        "    subg= nx.Graph()\n",
        "    for n,d in original_graph.nodes(data=True):\n",
        "        if fl in n.lower():\n",
        "            subg.add_node(n,**d)\n",
        "    for (u,v) in original_graph.edges():\n",
        "        if (u in subg.nodes) and (v in subg.nodes):\n",
        "            subg.add_edge(u,v,**original_graph[u][v])\n",
        "    return subg\n",
        "\n",
        "@app.route(\"/layer_hypergraph/<filter_str>\")\n",
        "def layer_hypergraph(filter_str):\n",
        "    global HYP_GRAPH\n",
        "    if not HYP_GRAPH:\n",
        "        return \"<h3>No HYP_GRAPH. Run first!</h3>\"\n",
        "    subg= build_subgraph_hyper(HYP_GRAPH, filter_str)\n",
        "    if subg.number_of_nodes()==0:\n",
        "        return f\"<h3>No hypergraph nodes match filter={filter_str}</h3>\"\n",
        "\n",
        "    net_h= Network(height=\"500px\", width=\"600px\", directed=False)\n",
        "    net_h.repulsion(node_distance=140, central_gravity=0.1)\n",
        "    for n,d in subg.nodes(data=True):\n",
        "        net_h.add_node(n, label=n, shape=\"dot\", size=20, borderWidth=1,\n",
        "                       title=n, color={\"border\":\"black\",\"background\":\"blue\"})\n",
        "    for (u,v) in subg.edges():\n",
        "        net_h.add_edge(u,v, color=\"gray\")\n",
        "\n",
        "    net_h.write_html(\"static/hypergraph_layer.html\", notebook=False, open_browser=False)\n",
        "    return f'<h2>Hypergraph filter={filter_str}</h2><iframe src=\"/static/hypergraph_layer.html\" width=\"600\" height=\"500\"></iframe>'\n",
        "\n",
        "@app.route(\"/layer_compgraph/<layer_str>\")\n",
        "def layer_compgraph(layer_str):\n",
        "    global COMP_GRAPH\n",
        "    if not COMP_GRAPH:\n",
        "        return \"<h3>No COMP_GRAPH. Run first!</h3>\"\n",
        "    try:\n",
        "        layer_num= int(layer_str)\n",
        "    except:\n",
        "        return f\"<h3>Invalid layer number: {layer_str}</h3>\"\n",
        "\n",
        "    subg= get_layer_subgraph(COMP_GRAPH, layer_num)\n",
        "    if subg.number_of_nodes()==0:\n",
        "        return f\"<h3>No compgraph BFS_distance={layer_num}</h3>\"\n",
        "\n",
        "    net_c= Network(height=\"500px\", width=\"600px\", directed=False)\n",
        "    net_c.repulsion(node_distance=140, central_gravity=0.1)\n",
        "    for n,d in subg.nodes(data=True):\n",
        "        BFS_d= d.get(\"BFS_distance\",0)\n",
        "        mem= d.get(\"mem\",0)\n",
        "        tmem= d.get(\"target_mem\",0)\n",
        "        tc= d.get(\"timecost\",0)\n",
        "        ttc= d.get(\"target_time\",0)\n",
        "        col= d.get(\"color\",\"blue\")\n",
        "        title_txt= f\"BFS={BFS_d}, mem={mem:.2f}->{tmem:.2f}, time={tc:.2f}->{ttc:.2f}\"\n",
        "        net_c.add_node(n, label=n, shape=\"dot\", size=20, borderWidth=1,\n",
        "                       title=title_txt, color={\"border\":\"black\",\"background\":col})\n",
        "    for (u,v) in subg.edges():\n",
        "        c= subg[u][v].get(\"color\",\"gray\")\n",
        "        net_c.add_edge(u,v, color=c)\n",
        "\n",
        "    net_c.write_html(\"static/compgraph_layer.html\", notebook=False, open_browser=False)\n",
        "    return f'<h2>CompGraph BFS={layer_num}</h2><iframe src=\"/static/compgraph_layer.html\" width=\"600\" height=\"500\"></iframe>'\n",
        "\n",
        "@app.route(\"/glossary_hyper\")\n",
        "def glossary_hyper():\n",
        "    global HYP_GRAPH\n",
        "    if not HYP_GRAPH or HYP_GRAPH.number_of_nodes()==0:\n",
        "        return \"<h2>No Hypergraph found</h2>\"\n",
        "\n",
        "    module_desc= {\n",
        "        \"attention\":\"Multi-head self-attention mechanism\",\n",
        "        \"ffn\":\"Feedforward network\",\n",
        "        \"layernorm\":\"LayerNorm for stable activations\",\n",
        "        \"dropout\":\"Regularization to prevent overfitting\",\n",
        "        \"embedding\":\"Embedding layer\",\n",
        "        \"pooler\":\"Pooling for final representation\"\n",
        "    }\n",
        "    table_html= \"<table border='1' cellpadding='6' cellspacing='0'><tr><th>Node</th><th>Description</th></tr>\"\n",
        "    for n in sorted(HYP_GRAPH.nodes()):\n",
        "        desc=\"General model component\"\n",
        "        low_n= n.lower()\n",
        "        for key in module_desc:\n",
        "            if key in low_n:\n",
        "                desc= module_desc[key]\n",
        "                break\n",
        "        table_html+= f\"<tr><td>{n}</td><td>{desc}</td></tr>\"\n",
        "    table_html+=\"</table>\"\n",
        "    return f\"<h2>Hypergraph Glossary</h2>{table_html}\"\n",
        "\n",
        "@app.route(\"/glossary_comp\")\n",
        "def glossary_comp():\n",
        "    global COMP_GRAPH, COMP_SHAPE_INFO\n",
        "    if not COMP_GRAPH or COMP_GRAPH.number_of_nodes()==0:\n",
        "        return \"<h2>No CompGraph found</h2>\"\n",
        "\n",
        "    table_html= \"<table border='1' cellpadding='6' cellspacing='0'><tr>\"\n",
        "    table_html+= \"<th>Node</th><th>Operation</th><th>BFS dist</th>\"\n",
        "    table_html+= \"<th>Input shape</th><th>Output shape</th><th>GPU Mem (KB)</th>\"\n",
        "    table_html+=\"</tr>\"\n",
        "\n",
        "    for n,d in sorted(COMP_GRAPH.nodes(data=True)):\n",
        "        bfs_d= d.get(\"BFS_distance\",\"?\")\n",
        "        op_type= interpret_operation(n)\n",
        "        in_shape,out_shape= COMP_SHAPE_INFO.get(n, (\"?\",\"?\"))\n",
        "        mem_kb= estimate_gpu_memory(n,out_shape)\n",
        "        table_html += f\"<tr><td>{n}</td><td>{op_type}</td><td>{bfs_d}</td>\"\n",
        "        table_html += f\"<td>{in_shape}</td><td>{out_shape}</td><td>{mem_kb}</td></tr>\"\n",
        "\n",
        "    table_html+=\"</table>\"\n",
        "    return f\"<h2>CompGraph Glossary</h2>{table_html}\"\n",
        "\n",
        "###############################################################################\n",
        "# EXPORTS\n",
        "###############################################################################\n",
        "\n",
        "def graph_to_json(nx_graph):\n",
        "    import networkx as nx\n",
        "    data_out= {\"nodes\":[],\"edges\":[]}\n",
        "    for n,d in nx_graph.nodes(data=True):\n",
        "        item={\"name\":n}\n",
        "        for k,v in d.items():\n",
        "            item[k]=v\n",
        "        data_out[\"nodes\"].append(item)\n",
        "    for s,t in nx_graph.edges():\n",
        "        e_data= nx_graph[s][t]\n",
        "        data_out[\"edges\"].append({\n",
        "            \"source\":s,\n",
        "            \"target\":t,\n",
        "            \"color\": e_data.get(\"color\",\"gray\")\n",
        "        })\n",
        "    return data_out\n",
        "\n",
        "def graph_to_csv(nx_graph):\n",
        "    import io\n",
        "    output= io.StringIO()\n",
        "    output.write(\"NODES\\n\")\n",
        "    output.write(\"name,BFS_distance,mem,target_mem,timecost,target_time,color\\n\")\n",
        "    for n,d in nx_graph.nodes(data=True):\n",
        "        bfs= d.get(\"BFS_distance\",\"\")\n",
        "        m  = d.get(\"mem\",\"\")\n",
        "        tm = d.get(\"target_mem\",\"\")\n",
        "        tc = d.get(\"timecost\",\"\")\n",
        "        ttc= d.get(\"target_time\",\"\")\n",
        "        col= d.get(\"color\",\"\")\n",
        "        output.write(f\"{n},{bfs},{m},{tm},{tc},{ttc},{col}\\n\")\n",
        "    output.write(\"\\nEDGES\\n\")\n",
        "    output.write(\"source,target,color\\n\")\n",
        "    for s,t in nx_graph.edges():\n",
        "        e_data= nx_graph[s][t]\n",
        "        c= e_data.get(\"color\",\"gray\")\n",
        "        output.write(f\"{s},{t},{c}\\n\")\n",
        "    csv_str= output.getvalue()\n",
        "    output.close()\n",
        "    return csv_str\n",
        "\n",
        "@app.route(\"/export_hypergraph\")\n",
        "def export_hypergraph_json():\n",
        "    global HYP_GRAPH\n",
        "    if not HYP_GRAPH:\n",
        "        return jsonify({\"error\":\"No hypergraph to export\"})\n",
        "    data_out= graph_to_json(HYP_GRAPH)\n",
        "    return jsonify({\"message\":\"Hypergraph exported\",\"data\":data_out})\n",
        "\n",
        "@app.route(\"/export_hypergraph_csv\")\n",
        "def export_hypergraph_csv():\n",
        "    global HYP_GRAPH\n",
        "    if not HYP_GRAPH:\n",
        "        return Response(\"No hypergraph to export\",status=400)\n",
        "    csv_str= graph_to_csv(HYP_GRAPH)\n",
        "    return Response(csv_str,mimetype=\"text/csv\",\n",
        "                    headers={\"Content-disposition\":\"attachment; filename=hypergraph_data.csv\"})\n",
        "\n",
        "@app.route(\"/export_comp_graph\")\n",
        "def export_comp_graph_json():\n",
        "    global COMP_GRAPH\n",
        "    if not COMP_GRAPH:\n",
        "        return jsonify({\"error\":\"No comp graph to export\"})\n",
        "    data_out= graph_to_json(COMP_GRAPH)\n",
        "    return jsonify({\"message\":\"CompGraph exported\",\"data\":data_out})\n",
        "\n",
        "@app.route(\"/export_comp_graph_csv\")\n",
        "def export_comp_graph_csv():\n",
        "    global COMP_GRAPH\n",
        "    if not COMP_GRAPH:\n",
        "        return Response(\"No comp graph to export\",status=400)\n",
        "    csv_str= graph_to_csv(COMP_GRAPH)\n",
        "    return Response(csv_str,mimetype=\"text/csv\",\n",
        "                    headers={\"Content-disposition\":\"attachment; filename=comp_graph_data.csv\"})\n",
        "\n",
        "@app.route(\"/export_q_table\")\n",
        "def export_q_table_api():\n",
        "    global Q_TABLE\n",
        "    data={}\n",
        "    for s in Q_TABLE:\n",
        "        data[str(s)] = Q_TABLE[s]\n",
        "    return jsonify({\"message\":\"Q-Table exported\",\"table\":data})\n",
        "\n",
        "@app.route(\"/export_q_table_csv\")\n",
        "def export_q_table_csv():\n",
        "    import io\n",
        "    global Q_TABLE\n",
        "    output= io.StringIO()\n",
        "    output.write(\"state,a0,a1,a2,a3\\n\")\n",
        "    for s in sorted(Q_TABLE.keys()):\n",
        "        row= [str(s)] + [str(val) for val in Q_TABLE[s]]\n",
        "        output.write(\",\".join(row)+\"\\n\")\n",
        "    csv_str= output.getvalue()\n",
        "    output.close()\n",
        "    return Response(csv_str,mimetype=\"text/csv\",\n",
        "                    headers={\"Content-disposition\":\"attachment; filename=q_table.csv\"})\n",
        "\n",
        "@app.route(\"/export_comp_graph_layer/<layer_str>\")\n",
        "def export_comp_graph_layer_json(layer_str):\n",
        "    global COMP_GRAPH\n",
        "    if not COMP_GRAPH:\n",
        "        return jsonify({\"error\":\"No COMP_GRAPH. Run first!\"})\n",
        "    try:\n",
        "        layer_num= int(layer_str)\n",
        "    except:\n",
        "        return jsonify({\"error\":f'Invalid layer number: {layer_str}'})\n",
        "    subg= get_layer_subgraph(COMP_GRAPH, layer_num)\n",
        "    if subg.number_of_nodes()==0:\n",
        "        return jsonify({\"error\":f'No comp graph BFS_distance={layer_num}'})\n",
        "    data_out= graph_to_json(subg)\n",
        "    return jsonify({\"message\":f'CompGraph BFS layer={layer_num}',\"data\":data_out})\n",
        "\n",
        "@app.route(\"/export_comp_graph_layer_csv/<layer_str>\")\n",
        "def export_comp_graph_layer_csv(layer_str):\n",
        "    global COMP_GRAPH\n",
        "    if not COMP_GRAPH:\n",
        "        return Response(\"No COMP_GRAPH. Run first!\",status=400)\n",
        "    try:\n",
        "        layer_num= int(layer_str)\n",
        "    except:\n",
        "        return Response(f\"Invalid layer number: {layer_str}\", status=400)\n",
        "    subg= get_layer_subgraph(COMP_GRAPH, layer_num)\n",
        "    if subg.number_of_nodes()==0:\n",
        "        return Response(f\"No compgraph BFS_distance={layer_num}\", status=400)\n",
        "    csv_str= graph_to_csv(subg)\n",
        "    return Response(\n",
        "        csv_str,\n",
        "        mimetype=\"text/csv\",\n",
        "        headers={\"Content-disposition\":f\"attachment; filename=compgraph_layer_{layer_num}.csv\"}\n",
        "    )\n",
        "\n",
        "###############################################################################\n",
        "# COLOR-CODING\n",
        "###############################################################################\n",
        "\n",
        "def mark_graph_changes(new_graph, old_graph):\n",
        "    if not old_graph:\n",
        "        for n in new_graph.nodes:\n",
        "            new_graph.nodes[n][\"color\"]=\"green\"\n",
        "        for e in new_graph.edges:\n",
        "            new_graph[e[0]][e[1]][\"color\"]=\"green\"\n",
        "        return\n",
        "\n",
        "    old_nodes= old_graph.nodes(data=True)\n",
        "    old_edges= set(old_graph.edges())\n",
        "\n",
        "    for n,d in new_graph.nodes(data=True):\n",
        "        if n not in old_graph:\n",
        "            d[\"color\"]=\"green\"\n",
        "        else:\n",
        "            old_data= old_nodes[n]\n",
        "            changed=False\n",
        "            fields= [\"BFS_distance\",\"mem\",\"timecost\",\"target_mem\",\"target_time\"]\n",
        "            for f in fields:\n",
        "                old_val= old_data.get(f,None)\n",
        "                new_val= d.get(f,None)\n",
        "                if old_val!=new_val:\n",
        "                    changed=True\n",
        "                    break\n",
        "            if changed:\n",
        "                d[\"color\"]=\"red\"\n",
        "            else:\n",
        "                d[\"color\"]=\"blue\"\n",
        "\n",
        "    new_edges= set(new_graph.edges())\n",
        "    for e in new_edges:\n",
        "        if e not in old_edges and (e[1],e[0]) not in old_edges:\n",
        "            new_graph[e[0]][e[1]][\"color\"]=\"green\"\n",
        "        else:\n",
        "            new_graph[e[0]][e[1]][\"color\"]=\"gray\"\n",
        "\n",
        "###############################################################################\n",
        "# DYNAMIC MEM/TIME => CONVERGENCE\n",
        "###############################################################################\n",
        "\n",
        "def converge_mem_time():\n",
        "    global COMP_GRAPH\n",
        "    alpha=0.3\n",
        "    if COMP_GRAPH:\n",
        "        for n,d in COMP_GRAPH.nodes(data=True):\n",
        "            if \"mem\" in d and \"target_mem\" in d:\n",
        "                old_m= d[\"mem\"]\n",
        "                tgt_m= d[\"target_mem\"]\n",
        "                d[\"mem\"]= old_m + alpha*(tgt_m- old_m)\n",
        "            if \"timecost\" in d and \"target_time\" in d:\n",
        "                old_t= d[\"timecost\"]\n",
        "                tgt_t= d[\"target_time\"]\n",
        "                d[\"timecost\"]= old_t + alpha*(tgt_t- old_t)\n",
        "\n",
        "def background_loop():\n",
        "    while True:\n",
        "        time.sleep(3)\n",
        "        converge_mem_time()\n",
        "\n",
        "bg_thread= threading.Thread(target=background_loop, daemon=True)\n",
        "bg_thread.start()\n",
        "\n",
        "###############################################################################\n",
        "# Node Drag => update target_mem/time\n",
        "###############################################################################\n",
        "\n",
        "@app.route(\"/update_node_position\", methods=[\"POST\"])\n",
        "def update_node_position():\n",
        "    global COMP_GRAPH, COMP_SHAPE_INFO\n",
        "    if not COMP_GRAPH:\n",
        "        return jsonify({\"error\":\"No comp graph\"})\n",
        "\n",
        "    data= request.get_json(force=True)\n",
        "    node_id= data.get(\"node\",\"\")\n",
        "    x_pos= float(data.get(\"x\",0))\n",
        "    y_pos= float(data.get(\"y\",0))\n",
        "\n",
        "    if node_id not in COMP_GRAPH:\n",
        "        return jsonify({\"error\":f'Node {node_id} not in comp graph'})\n",
        "\n",
        "    # BFS root\n",
        "    root_candidates= [n for n in COMP_GRAPH.nodes if COMP_GRAPH.nodes[n].get(\"BFS_distance\",0)==0]\n",
        "    if not root_candidates:\n",
        "        compute_bfs_levels(COMP_GRAPH)\n",
        "        root_candidates= [n for n in COMP_GRAPH.nodes if COMP_GRAPH.nodes[n].get(\"BFS_distance\",0)==0]\n",
        "    root_node= root_candidates[0]\n",
        "\n",
        "    COMP_GRAPH.nodes[node_id][\"x\"]= x_pos\n",
        "    COMP_GRAPH.nodes[node_id][\"y\"]= y_pos\n",
        "\n",
        "    rx= COMP_GRAPH.nodes[root_node].get(\"x\",0)\n",
        "    ry= COMP_GRAPH.nodes[root_node].get(\"y\",0)\n",
        "    dx= x_pos- rx\n",
        "    dy= y_pos- ry\n",
        "    dist= (dx*dx+ dy*dy)**0.5\n",
        "\n",
        "    BFS_d= COMP_GRAPH.nodes[node_id].get(\"BFS_distance\",0)\n",
        "\n",
        "    # shape-based memory\n",
        "    shape_inp, shape_out= COMP_SHAPE_INFO.get(node_id, (\"?\",\"?\"))\n",
        "    shape_mem= 0.0\n",
        "    if isinstance(shape_out, tuple):\n",
        "        numel=1\n",
        "        for dim in shape_out:\n",
        "            numel*= dim\n",
        "        shape_mem= (numel*4)/1024  # in KB ?\n",
        "\n",
        "    BFS_factor= BFS_d+1\n",
        "    new_target_mem= shape_mem + BFS_factor * dist\n",
        "    new_target_time= BFS_factor * dist * 2\n",
        "\n",
        "    COMP_GRAPH.nodes[node_id][\"target_mem\"]= new_target_mem\n",
        "    COMP_GRAPH.nodes[node_id][\"target_time\"]= new_target_time\n",
        "    COMP_GRAPH.nodes[node_id][\"geomDist\"]= dist\n",
        "    COMP_GRAPH.nodes[node_id][\"color\"]= \"red\"\n",
        "\n",
        "    return jsonify({\n",
        "        \"message\":\"Node updated\",\n",
        "        \"node\": node_id,\n",
        "        \"BFS_d\": BFS_d,\n",
        "        \"dist\": dist,\n",
        "        \"shape_mem_kb\": shape_mem,\n",
        "        \"target_mem\": new_target_mem,\n",
        "        \"target_time\": new_target_time\n",
        "    })\n",
        "\n",
        "###############################################################################\n",
        "# Real-time Poll => memory/time\n",
        "###############################################################################\n",
        "\n",
        "@app.route(\"/poll_compgraph_data\")\n",
        "def poll_compgraph_data():\n",
        "    \"\"\"\n",
        "    Returns BFS_distance, mem, timecost for each node.\n",
        "    The front-end uses setInterval to poll & update tooltips every 3s\n",
        "    \"\"\"\n",
        "    global COMP_GRAPH\n",
        "    if not COMP_GRAPH:\n",
        "        return jsonify({})\n",
        "    out = {}\n",
        "    for n,d in COMP_GRAPH.nodes(data=True):\n",
        "        out[n] = {\n",
        "            \"BFS_distance\": d.get(\"BFS_distance\",0),\n",
        "            \"mem\": round(d.get(\"mem\",0), 2),\n",
        "            \"timecost\": round(d.get(\"timecost\",0), 2)\n",
        "        }\n",
        "    return jsonify(out)\n",
        "\n",
        "###############################################################################\n",
        "# MAIN PAGE\n",
        "###############################################################################\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\",\"POST\"])\n",
        "def single_page():\n",
        "    global HYP_GRAPH, COMP_GRAPH, OLD_HYP_GRAPH, OLD_COMP_GRAPH\n",
        "    global COMP_SHAPE_INFO, CONVERSATION, RL_CHOICE\n",
        "\n",
        "    subgraph_html=\"\"\n",
        "\n",
        "    try:\n",
        "        if request.method==\"POST\":\n",
        "            model_label= request.form.get(\"model\",\"BERT (base)\")\n",
        "            hf_id     = AVAILABLE_MODELS.get(model_label,\"bert-base-uncased\")\n",
        "            gpu_sel   = request.form.get(\"gpu\",\"T4\")\n",
        "            quant     = request.form.get(\"quant\",\"None (FP32)\")\n",
        "            reasoning = request.form.get(\"reason\",\"No reasoning\")\n",
        "            rl_algo   = request.form.get(\"rl_algo\",\"No RL\")\n",
        "            RL_CHOICE = rl_algo\n",
        "            user_txt  = request.form.get(\"textinput\",\"\").strip()\n",
        "            act       = request.form.get(\"act\",\"run\")\n",
        "\n",
        "            layer_input= request.form.get(\"layer_input\",\"\").strip()\n",
        "            hyper_filter= request.form.get(\"hyper_filter\",\"\").strip()\n",
        "\n",
        "            # NEW: sequence length\n",
        "            seq_len_input= request.form.get(\"seq_len\",\"\").strip()\n",
        "            try:\n",
        "                seq_len= int(seq_len_input)\n",
        "                if seq_len<1:\n",
        "                    seq_len= 1\n",
        "            except:\n",
        "                seq_len= 32  # default\n",
        "\n",
        "            model, tok = load_model(hf_id, quant)\n",
        "\n",
        "            if rl_algo!=\"No RL\":\n",
        "                s= random.randint(0,9)\n",
        "                a= random.randint(0,3)\n",
        "                r= random.uniform(-1,1)\n",
        "                update_q_table(s,a,r)\n",
        "                CONVERSATION.append(f\"RL({rl_algo}): Updated Q => s={s}, a={a}, r={r:.2f}\")\n",
        "            else:\n",
        "                CONVERSATION.append(\"RL disabled (No RL).\")\n",
        "\n",
        "            if user_txt:\n",
        "                CONVERSATION.append(f\"User(Text): {user_txt}\")\n",
        "\n",
        "            if act==\"run\":\n",
        "                new_hyp= extract_hypergraph(model, quant, reasoning)\n",
        "                new_comp= extract_comp_graph(model, tok, gpu_sel, quant, reasoning)\n",
        "                compute_bfs_levels(new_comp)\n",
        "                mark_graph_changes(new_hyp, OLD_HYP_GRAPH)\n",
        "                mark_graph_changes(new_comp, OLD_COMP_GRAPH)\n",
        "                HYP_GRAPH= new_hyp\n",
        "                COMP_GRAPH= new_comp\n",
        "                OLD_HYP_GRAPH= new_hyp.copy()\n",
        "                OLD_COMP_GRAPH= new_comp.copy()\n",
        "\n",
        "                # shape trace\n",
        "                shape_dict= trace_model_fx(model,tok)\n",
        "                COMP_SHAPE_INFO.clear()\n",
        "                for node_name,(inp,outp) in shape_dict.items():\n",
        "                    nm= \"COMP_\"+ node_name\n",
        "                    COMP_SHAPE_INFO[nm]= (inp,outp)\n",
        "\n",
        "                scale_factor = GPU_MEMORY_SCALE.get(gpu_sel,1.0)\n",
        "                # Assign initial distinct mem/time with new approximate_time_complexity\n",
        "                for n,d in COMP_GRAPH.nodes(data=True):\n",
        "                    BFS_d= d[\"BFS_distance\"]\n",
        "                    node_name= n.replace(\"COMP_\",\"\")\n",
        "\n",
        "                    # shape-based memory\n",
        "                    shape_in, shape_out= shape_dict.get(node_name, (\"?\",\"?\"))\n",
        "                    shape_mem= 0.0\n",
        "                    if isinstance(shape_out, tuple):\n",
        "                        numel=1\n",
        "                        for dim in shape_out:\n",
        "                            numel*= dim\n",
        "                        shape_mem= (numel*4)/1024.0\n",
        "\n",
        "                    # time complexity (just an integer cost)\n",
        "                    node_time= approximate_time_complexity(node_name, reasoning, seq_len)\n",
        "\n",
        "                    mem_init= (BFS_d+1)* shape_mem * scale_factor\n",
        "                    time_init= (BFS_d+1)* node_time\n",
        "\n",
        "                    d[\"mem\"] = mem_init\n",
        "                    d[\"target_mem\"] = mem_init\n",
        "                    d[\"timecost\"] = time_init\n",
        "                    d[\"target_time\"] = time_init * 1.5  # e.g. so we have a separate target\n",
        "\n",
        "                CONVERSATION.append(f\"Action: run => BFS + shape + seq_len={seq_len} => assigned mem/time\")\n",
        "\n",
        "            elif act==\"fine_tune\":\n",
        "                toy_finetune(model)\n",
        "                new_hyp= extract_hypergraph(model, quant, reasoning)\n",
        "                new_comp= extract_comp_graph(model, tok, gpu_sel, quant, reasoning)\n",
        "                compute_bfs_levels(new_comp)\n",
        "                mark_graph_changes(new_hyp,OLD_HYP_GRAPH)\n",
        "                mark_graph_changes(new_comp,OLD_COMP_GRAPH)\n",
        "                HYP_GRAPH= new_hyp\n",
        "                COMP_GRAPH= new_comp\n",
        "                OLD_HYP_GRAPH= new_hyp.copy()\n",
        "                OLD_COMP_GRAPH= new_comp.copy()\n",
        "\n",
        "                shape_dict= trace_model_fx(model,tok)\n",
        "                COMP_SHAPE_INFO.clear()\n",
        "                for node_name,(inp,outp) in shape_dict.items():\n",
        "                    nm=\"COMP_\"+ node_name\n",
        "                    COMP_SHAPE_INFO[nm]=(inp,outp)\n",
        "\n",
        "                scale_factor = GPU_MEMORY_SCALE.get(gpu_sel,1.0)\n",
        "                for n,d in COMP_GRAPH.nodes(data=True):\n",
        "                    BFS_d= d[\"BFS_distance\"]\n",
        "                    node_name= n.replace(\"COMP_\",\"\")\n",
        "                    shape_in, shape_out= shape_dict.get(node_name, (\"?\",\"?\"))\n",
        "                    shape_mem=0\n",
        "                    if isinstance(shape_out, tuple):\n",
        "                        numel=1\n",
        "                        for dim in shape_out:\n",
        "                            numel*= dim\n",
        "                        shape_mem= (numel*4)/1024.0\n",
        "                    node_time= approximate_time_complexity(node_name, reasoning, seq_len)\n",
        "                    mem_init= (BFS_d+1)* shape_mem* scale_factor\n",
        "                    time_init= (BFS_d+1)* node_time\n",
        "                    d[\"mem\"]= mem_init\n",
        "                    d[\"target_mem\"]= mem_init\n",
        "                    d[\"timecost\"]= time_init\n",
        "                    d[\"target_time\"]= time_init*1.5\n",
        "\n",
        "                CONVERSATION.append(f\"Action: fine_tune => done + seq_len={seq_len} => mem/time assigned\")\n",
        "\n",
        "            elif act==\"speak\":\n",
        "                new_hyp= extract_hypergraph(model, quant, reasoning)\n",
        "                new_comp= extract_comp_graph(model, tok, gpu_sel, quant, reasoning)\n",
        "                compute_bfs_levels(new_comp)\n",
        "                mark_graph_changes(new_hyp,OLD_HYP_GRAPH)\n",
        "                mark_graph_changes(new_comp,OLD_COMP_GRAPH)\n",
        "                HYP_GRAPH= new_hyp\n",
        "                COMP_GRAPH= new_comp\n",
        "                OLD_HYP_GRAPH= new_hyp.copy()\n",
        "                OLD_COMP_GRAPH= new_comp.copy()\n",
        "\n",
        "                shape_dict= trace_model_fx(model,tok)\n",
        "                COMP_SHAPE_INFO.clear()\n",
        "                for node_name,(inp,outp) in shape_dict.items():\n",
        "                    nm=\"COMP_\"+node_name\n",
        "                    COMP_SHAPE_INFO[nm]=(inp,outp)\n",
        "\n",
        "                scale_factor = GPU_MEMORY_SCALE.get(gpu_sel,1.0)\n",
        "                for n,d in COMP_GRAPH.nodes(data=True):\n",
        "                    BFS_d= d[\"BFS_distance\"]\n",
        "                    node_name= n.replace(\"COMP_\",\"\")\n",
        "                    shape_in, shape_out= shape_dict.get(node_name, (\"?\",\"?\"))\n",
        "                    shape_mem=0\n",
        "                    if isinstance(shape_out, tuple):\n",
        "                        numel=1\n",
        "                        for dim in shape_out:\n",
        "                            numel*= dim\n",
        "                        shape_mem= (numel*4)/1024.0\n",
        "                    node_time= approximate_time_complexity(node_name, reasoning, seq_len)\n",
        "                    mem_init= (BFS_d+1)* shape_mem* scale_factor\n",
        "                    time_init= (BFS_d+1)* node_time\n",
        "                    d[\"mem\"]= mem_init\n",
        "                    d[\"target_mem\"]= mem_init\n",
        "                    d[\"timecost\"]= time_init\n",
        "                    d[\"target_time\"]= time_init*1.5\n",
        "\n",
        "                CONVERSATION.append(f\"Action: speak => placeholder => seq_len={seq_len} => mem/time assigned\")\n",
        "\n",
        "            elif act==\"layer_view\":\n",
        "                if COMP_GRAPH:\n",
        "                    try:\n",
        "                        ln= int(layer_input)\n",
        "                        subg= get_layer_subgraph(COMP_GRAPH, ln)\n",
        "                        if subg.number_of_nodes()==0:\n",
        "                            subgraph_html= f\"<h4>No compgraph BFS_distance={ln}</h4>\"\n",
        "                        else:\n",
        "                            from pyvis.network import Network\n",
        "                            net_c= Network(height='500px',width='600px',directed=False)\n",
        "                            net_c.repulsion(node_distance=140,central_gravity=0.1)\n",
        "                            for n,d in subg.nodes(data=True):\n",
        "                                BFS_d= d.get(\"BFS_distance\",0)\n",
        "                                m= d.get(\"mem\",0)\n",
        "                                tm= d.get(\"target_mem\",0)\n",
        "                                t= d.get(\"timecost\",0)\n",
        "                                tt= d.get(\"target_time\",0)\n",
        "                                col= d.get(\"color\",\"blue\")\n",
        "                                title_txt= f\"BFS={BFS_d}, mem={m:.2f}->{tm:.2f}, time={t:.2f}->{tt:.2f}\"\n",
        "                                net_c.add_node(n,label=n,shape=\"dot\",size=20,borderWidth=1,\n",
        "                                               title=title_txt,\n",
        "                                               color={\"border\":\"black\",\"background\":col})\n",
        "                            for (u,v) in subg.edges():\n",
        "                                c= subg[u][v].get(\"color\",\"gray\")\n",
        "                                net_c.add_edge(u,v,color=c)\n",
        "                            net_c.write_html(\"static/layer_view.html\", notebook=False, open_browser=False)\n",
        "                            subgraph_html= f\"<h3>CompGraph BFS layer={ln}</h3><iframe src='/static/layer_view.html' width='600' height='500'></iframe>\"\n",
        "                    except:\n",
        "                        subgraph_html= f\"<h4>Invalid BFS layer: {layer_input}</h4>\"\n",
        "                else:\n",
        "                    subgraph_html= \"<h4>No COMP_GRAPH available, please run first!</h4>\"\n",
        "\n",
        "            elif act==\"hyper_filter_view\":\n",
        "                if HYP_GRAPH:\n",
        "                    from pyvis.network import Network\n",
        "                    subg= build_subgraph_hyper(HYP_GRAPH, hyper_filter)\n",
        "                    if subg.number_of_nodes()==0:\n",
        "                        subgraph_html= f\"<h4>No hypergraph nodes match '{hyper_filter}'</h4>\"\n",
        "                    else:\n",
        "                        net_h= Network(height='500px',width='600px',directed=False)\n",
        "                        net_h.repulsion(node_distance=140,central_gravity=0.1)\n",
        "                        for n,d in subg.nodes(data=True):\n",
        "                            net_h.add_node(n,label=n,shape=\"dot\",size=20,borderWidth=1,\n",
        "                                           title=n,color={\"border\":\"black\",\"background\":\"blue\"})\n",
        "                        for (u,v) in subg.edges():\n",
        "                            net_h.add_edge(u,v,color=\"gray\")\n",
        "                        net_h.write_html(\"static/hyper_filter_view.html\",notebook=False,open_browser=False)\n",
        "                        subgraph_html= f\"<h3>Hypergraph filter='{hyper_filter}'</h3><iframe src='/static/hyper_filter_view.html' width='600' height='500'></iframe>\"\n",
        "                else:\n",
        "                    subgraph_html= \"<h4>No HYP_GRAPH available, please run first!</h4>\"\n",
        "\n",
        "        graph_html=\"\"\n",
        "        if HYP_GRAPH and COMP_GRAPH:\n",
        "            from pyvis.network import Network\n",
        "            if \"BFS_distance\" not in list(COMP_GRAPH.nodes(data=True))[0][1]:\n",
        "                compute_bfs_levels(COMP_GRAPH)\n",
        "\n",
        "            # Build hypergraph\n",
        "            net_h = Network(height='500px', width='600px', directed=False)\n",
        "            net_h.repulsion(node_distance=140, central_gravity=0.1)\n",
        "            for n,d in HYP_GRAPH.nodes(data=True):\n",
        "                col= d.get(\"color\",\"blue\")\n",
        "                net_h.add_node(n,label=n,shape=\"dot\",size=20,borderWidth=1,\n",
        "                               title=n,color={\"border\":\"black\",\"background\":col})\n",
        "            for s,t in HYP_GRAPH.edges():\n",
        "                c= HYP_GRAPH[s][t].get(\"color\",\"gray\")\n",
        "                net_h.add_edge(s,t,color=c)\n",
        "            net_h.write_html(\"static/hypergraph.html\", notebook=False, open_browser=False)\n",
        "\n",
        "            # Build compgraph\n",
        "            net_c = Network(height='500px', width='600px', directed=False)\n",
        "            net_c.repulsion(node_distance=140, central_gravity=0.1)\n",
        "            for n,d in COMP_GRAPH.nodes(data=True):\n",
        "                BFS_d= d.get(\"BFS_distance\",0)\n",
        "                m   = d.get(\"mem\",0)\n",
        "                tm  = d.get(\"target_mem\",0)\n",
        "                t   = d.get(\"timecost\",0)\n",
        "                tt  = d.get(\"target_time\",0)\n",
        "                col = d.get(\"color\",\"blue\")\n",
        "                title_txt= f\"BFS={BFS_d}, mem={m:.2f}->{tm:.2f}, time={t:.2f}->{tt:.2f}\"\n",
        "                net_c.add_node(n,label=n,shape=\"dot\",size=20,borderWidth=1,\n",
        "                               title=title_txt,color={\"border\":\"black\",\"background\":col})\n",
        "            for (u,v) in COMP_GRAPH.edges():\n",
        "                e_col= COMP_GRAPH[u][v].get(\"color\",\"gray\")\n",
        "                net_c.add_edge(u,v,color=e_col)\n",
        "            net_c.write_html(\"static/compgraph.html\", notebook=False, open_browser=False)\n",
        "\n",
        "            # Insert the \"drag\" script + \"poll\" script for real-time updates\n",
        "            with open(\"static/compgraph.html\",\"r\") as f:\n",
        "                comp_html= f.read()\n",
        "\n",
        "            drag_js= \"\"\"\n",
        "<script>\n",
        "  var throttleTimeout = null;\n",
        "  network.on(\"drag\", function(params) {\n",
        "    if (params.nodes.length > 0) {\n",
        "      if (throttleTimeout) { return; }\n",
        "      throttleTimeout = setTimeout(()=>{\n",
        "        throttleTimeout=null;\n",
        "        let nodeId= params.nodes[0];\n",
        "        let nodePos= network.getPosition(nodeId);\n",
        "        fetch(\"/update_node_position\", {\n",
        "          method:\"POST\",\n",
        "          headers: {\"Content-Type\":\"application/json\"},\n",
        "          body: JSON.stringify({\"node\":nodeId, \"x\":nodePos.x, \"y\":nodePos.y})\n",
        "        })\n",
        "        .then(resp=>resp.json())\n",
        "        .then(dat=>{\n",
        "          console.log(\"Dragging => new target mem/time:\",dat);\n",
        "          let BFS_d= dat.BFS_d;\n",
        "          let dist= dat.dist.toFixed(2);\n",
        "          let shapeM= dat.shape_mem_kb.toFixed(2);\n",
        "          let mem= dat.target_mem.toFixed(2);\n",
        "          let timeC= dat.target_time.toFixed(2);\n",
        "          let newTitle= \"BFS=\"+BFS_d+\", dist=\"+dist+\", shapeMem=\"+shapeM+\" KB, mem->\"+mem+\", time->\"+timeC;\n",
        "          network.body.nodes[nodeId].options.title= newTitle;\n",
        "          network.redraw();\n",
        "        })\n",
        "        .catch(err=>console.error(err));\n",
        "      }, 150);\n",
        "    }\n",
        "  });\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "            poll_js= \"\"\"\n",
        "<script>\n",
        "  // Poll every 3s to get updated mem/time and update tooltips\n",
        "  setInterval(()=>{\n",
        "    fetch(\"/poll_compgraph_data\")\n",
        "    .then(r=>r.json())\n",
        "    .then(dat=>{\n",
        "       for(let nodeId in dat) {\n",
        "         let BFS_d = dat[nodeId].BFS_distance;\n",
        "         let mem   = dat[nodeId].mem.toFixed(2);\n",
        "         let timeC = dat[nodeId].timecost.toFixed(2);\n",
        "         // If the node is in the network, update tooltip\n",
        "         if(network.body.nodes[nodeId]) {\n",
        "            let newTitle= \"BFS=\"+BFS_d+\", mem=\"+mem+\", time=\"+timeC;\n",
        "            network.body.nodes[nodeId].options.title= newTitle;\n",
        "         }\n",
        "       }\n",
        "       network.redraw();\n",
        "    })\n",
        "    .catch(err=>console.error(err));\n",
        "  }, 3000);\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "            comp_html= comp_html.replace(\"</body>\", drag_js + \"\\n\" + poll_js + \"\\n</body>\")\n",
        "\n",
        "            with open(\"static/compgraph.html\",\"w\") as f:\n",
        "                f.write(comp_html)\n",
        "\n",
        "            graph_html= f\"\"\"\n",
        "<div style=\"margin:auto; width:90%; text-align:center;\">\n",
        "  <table style=\"margin:auto;\"><tr>\n",
        "     <td valign=\"top\">\n",
        "        <h2>Hypergraph</h2>\n",
        "        <iframe src=\"/static/hypergraph.html\" width=\"600\" height=\"500\"></iframe>\n",
        "        <p><a href=\"/glossary_hyper\" target=\"_blank\">Hypergraph Glossary</a></p>\n",
        "     </td>\n",
        "     <td valign=\"top\">\n",
        "        <h2>Computational Graph</h2>\n",
        "        <iframe src=\"/static/compgraph.html\" width=\"600\" height=\"500\"></iframe>\n",
        "        <p><a href=\"/glossary_comp\" target=\"_blank\">CompGraph Glossary</a></p>\n",
        "        <p><i>Drag nodes to set new mem/time targets.<br>\n",
        "        Memory/time also converge in the background over time,<br>\n",
        "        so watch real-time updates in the node tooltips!</i></p>\n",
        "     </td>\n",
        "  </tr></table>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin:auto; width:90%; text-align:center;\">\n",
        "  <h2>Q-Space Heatmap (2D)</h2>\n",
        "  <img src=\"/q_space\" alt=\"Q Heatmap\"/>\n",
        "  <br><a href=\"/q_space_interactive\" target=\"_blank\">3D Q-Space (click to open)</a>\n",
        "  <p>You can rotate the 3D Q-Space by clicking/dragging in the plot.</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin:auto; width:90%; text-align:center;\">\n",
        "  <p>\n",
        "  <strong>Exports:</strong><br/>\n",
        "  <a href=\"/export_hypergraph\" target=\"_blank\">Hypergraph JSON</a> |\n",
        "  <a href=\"/export_hypergraph_csv\" target=\"_blank\">Hypergraph CSV</a><br/>\n",
        "  <a href=\"/export_comp_graph\" target=\"_blank\">CompGraph JSON</a> |\n",
        "  <a href=\"/export_comp_graph_csv\" target=\"_blank\">CompGraph CSV</a><br/>\n",
        "  <a href=\"/export_q_table\" target=\"_blank\">Q-Table JSON</a> |\n",
        "  <a href=\"/export_q_table_csv\" target=\"_blank\">Q-Table CSV</a>\n",
        "  </p>\n",
        "  <p>\n",
        "    <strong>Subgraph routes</strong>:<br/>\n",
        "    /layer_compgraph/0 => BFS=0 subgraph.<br/>\n",
        "    /layer_hypergraph/attention => substring filter\n",
        "  </p>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "        style_center= \"style='text-align:center; margin:auto; width:90%;'\"\n",
        "        model_opts= \"\".join([f'<option value=\"{lbl}\">{lbl}</option>' for lbl in AVAILABLE_MODELS])\n",
        "        gpu_opts= \"\".join([f'<option value=\"{gp}\">{gp}</option>' for gp in AVAILABLE_GPUS])\n",
        "        quant_opts= \"\".join([f'<option value=\"{qq}\">{qq}</option>' for qq in QUANT_METHODS])\n",
        "        reas_opts= \"\".join([f'<option value=\"{rr}\">{rr}</option>' for rr in REASONING_METHODS])\n",
        "        rl_opts= \"\".join([f'<option value=\"{alg}\">{alg}</option>' for alg in RL_ALGORITHMS])\n",
        "\n",
        "        html= f\"<html><head><title>AI Interpretability</title></head><body {style_center}>\"\n",
        "        html+= \"<h1>AI Interpretability (Enhanced Time Complexity)</h1>\"\n",
        "        html+= \"<form method='post'>\"\n",
        "        html+= \"<label>Model:</label>\"\n",
        "        html+= f\"<select name='model'>{model_opts}</select>\"\n",
        "        html+= \"<label> GPU:</label>\"\n",
        "        html+= f\"<select name='gpu'>{gpu_opts}</select>\"\n",
        "        html+= \"<label> Quant:</label>\"\n",
        "        html+= f\"<select name='quant'>{quant_opts}</select>\"\n",
        "        html+= \"<label> Reasoning:</label>\"\n",
        "        html+= f\"<select name='reason'>{reas_opts}</select>\"\n",
        "        html+= \"<label> RL:</label>\"\n",
        "        html+= f\"<select name='rl_algo'>{rl_opts}</select>\"\n",
        "        html+= \"<br><br>\"\n",
        "\n",
        "        # new field for seq_len\n",
        "        html+= \"<label>Sequence Length (n): </label>\"\n",
        "        html+= '<input name=\"seq_len\" placeholder=\"32\" style=\"width:60px;\"/>'\n",
        "        html+= \"<br><br>\"\n",
        "\n",
        "        html+= '<textarea name=\"textinput\" rows=\"3\" cols=\"60\" placeholder=\"Type text here...\"></textarea><br><br>'\n",
        "\n",
        "        html+= \"<button name='act' value='run'>Run</button> \"\n",
        "        html+= \"<button name='act' value='fine_tune'>Fine-Tune</button> \"\n",
        "        html+= \"<button name='act' value='speak'>Speak</button> \"\n",
        "\n",
        "        html+= \"<hr><h3>View BFS Layer of CompGraph</h3>\"\n",
        "        html+= '(0 = input layer only)<br>'\n",
        "        html+= '<input name=\"layer_input\" placeholder=\"1\" /> '\n",
        "        html+= '<button name=\"act\" value=\"layer_view\">Show CompGraph Subgraph</button>'\n",
        "\n",
        "        html+= \"<hr><h3>Hypergraph Filter</h3>\"\n",
        "        html+= '<input name=\"hyper_filter\" placeholder=\"attention or layer.1\" /> '\n",
        "        html+= '<button name=\"act\" value=\"hyper_filter_view\">Show Hypergraph Filter</button>'\n",
        "\n",
        "        html+= \"</form>\"\n",
        "\n",
        "        html+= \"<h2>Conversation Log</h2>\"\n",
        "        for line in CONVERSATION:\n",
        "            html+= f\"<p>{line}</p>\"\n",
        "        html+= \"<br>\"\n",
        "\n",
        "        html+= subgraph_html\n",
        "        html+= graph_html\n",
        "\n",
        "        html+= \"</body></html>\"\n",
        "        return html\n",
        "\n",
        "    except Exception as ex:\n",
        "        tb= traceback.format_exc()\n",
        "        CONVERSATION.append(f\"[ERROR]: {tb}\")\n",
        "        return f\"<h3>Internal Server Error</h3><pre>{tb}</pre>\", 500\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    print(\"Starting Flask on port=8000, debug=False ...\")\n",
        "    app.run(host=\"0.0.0.0\", port=8000, debug=False)\n",
        "'''\n",
        "\n",
        "# Write interpret_flask.py\n",
        "with open(\"interpret_flask.py\",\"w\") as f:\n",
        "    f.write(FULL_CODE)\n",
        "\n",
        "print(\"âœ… Wrote interpret_flask.py (Enhanced Time Complexity). Starting flask in background...\")\n",
        "\n",
        "# Start Flask in background\n",
        "!nohup python interpret_flask.py > server.log 2>&1 &\n",
        "\n",
        "print(\"â³ Polling localhost:8000 for up to 30s to confirm server up...\")\n",
        "\n",
        "ready=False\n",
        "for i in range(30):\n",
        "    time.sleep(1)\n",
        "    try:\n",
        "        r = requests.get(\"http://127.0.0.1:8000\")\n",
        "        if r.status_code==200:\n",
        "            print(f\"âœ… Flask responded after {i+1} sec. Proceeding.\")\n",
        "            ready=True\n",
        "            break\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if not ready:\n",
        "    print(\"âš ï¸ Could not confirm flask is up after 30s. Attempting ngrok anyway...\")\n",
        "\n",
        "print(\"ðŸ”— Start ngrok =>\")\n",
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"2tedizGJDmEJMDtfhCR6ftx8EyX_2RaA7t8nPn17SU7jiyK1H\"  # Replace with your token\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"ðŸŒ Public URL =>\", public_url)\n",
        "\n",
        "print(\"âœ… Done. Check the logs if needed =>\")\n",
        "time.sleep(2)\n",
        "!tail -n 20 server.log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzvsvh4JI2Z7",
        "outputId": "4431ebc0-b077-41a8-aab3-1e46c30c15d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”´ Killing anything on port=8000 + old ngrok sessions.\n",
            "^C\n",
            "ðŸ“¦ Installing dependencies (quietly)...\n",
            "âœ… Wrote interpret_flask.py (Enhanced Time Complexity). Starting flask in background...\n",
            "â³ Polling localhost:8000 for up to 30s to confirm server up...\n",
            "âœ… Flask responded after 5 sec. Proceeding.\n",
            "ðŸ”— Start ngrok =>\n",
            "ðŸŒ Public URL => NgrokTunnel: \"https://a744-34-87-155-94.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "âœ… Done. Check the logs if needed =>\n",
            "Starting Flask on port=8000, debug=False ...\n",
            " * Serving Flask app 'interpret_flask'\n",
            " * Debug mode: off\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://172.28.0.12:8000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [05/Mar/2025 03:43:22] \"GET / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}